{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "79a241a8-c715-4c20-b688-5e084ed30d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "from transformers.optimization import Adafactor\n",
    "import time\n",
    "import warnings\n",
    "from IPython.display import HTML, display\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fa291755-3b66-446c-b64c-e5479c0de502",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7e77e38c-8de1-46a9-8af3-dde4230c1b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContentGenerator():\n",
    "    def __init__(self):\n",
    "        self.batch_size = 8\n",
    "        self.num_of_epochs = 10\n",
    "        self.checkpoint_path = 'checkpoint/reviews-model.bin'\n",
    "        self.config_path = 'data/t5-base-config.json'\n",
    "    \n",
    "    def getData(self):\n",
    "        self.train_df = pd.read_csv('data/review_keywords_All_Beauty_5.csv')\n",
    "        self.train_df = self.train_df[:500]\n",
    "        self.num_of_batches = int(len(self.train_df)/self.batch_size)\n",
    "        # print(self.train_df)\n",
    "        \n",
    "    def getDevice(self):\n",
    "        if torch.cuda.is_available():\n",
    "            self.dev = torch.device(\"cuda:0\")\n",
    "            print(\"Running on the GPU\")\n",
    "        else:\n",
    "            self.dev = torch.device(\"cpu\")\n",
    "            print(\"Running on the CPU\")\n",
    "    \n",
    "    def getTokenizer(self):\n",
    "        self.tokenizer = T5Tokenizer.from_pretrained('t5-base')\n",
    "    \n",
    "    def getModel(self):\n",
    "        self.getData()\n",
    "        self.getDevice()\n",
    "        self.getTokenizer()\n",
    "        self.model = T5ForConditionalGeneration.from_pretrained('t5-base', return_dict=True)\n",
    "        self.model.to(self.dev)\n",
    "        self.optimizer = Adafactor(\n",
    "            self.model.parameters(),\n",
    "            lr=1e-3,\n",
    "            eps=(1e-30, 1e-3),\n",
    "            clip_threshold=1.0,\n",
    "            decay_rate=-0.8,\n",
    "            beta1=None,\n",
    "            weight_decay=0.0,\n",
    "            relative_step=False,\n",
    "            scale_parameter=False,\n",
    "            warmup_init=False\n",
    "        )\n",
    "        \n",
    "    def progress(self, loss,value, max=100):\n",
    "        return HTML(\"\"\" Batch loss :{loss}\n",
    "            <progress\n",
    "                value='{value}'\n",
    "                max='{max}',\n",
    "                style='width: 100%'\n",
    "            >\n",
    "                {value}\n",
    "            </progress>\n",
    "        \"\"\".format(loss=loss,value=value, max=max))\n",
    "    \n",
    "    def fit(self):\n",
    "        self.getModel()\n",
    "        self.model.train()\n",
    "        self.train_df = self.train_df.dropna()\n",
    "        loss_per_10_steps=[]\n",
    "        for epoch in range(1, self.num_of_epochs+1):\n",
    "            print('Running epoch: {}'.format(epoch))\n",
    "            running_loss=0\n",
    "\n",
    "            out = display(self.progress(1, self.num_of_batches+1), display_id=True)\n",
    "            for i in range(self.num_of_batches):\n",
    "                inputbatch = []\n",
    "                labelbatch = []\n",
    "                new_df = self.train_df[i*self.batch_size:i*self.batch_size+self.batch_size]\n",
    "                for indx,row in new_df.iterrows():\n",
    "                    input = 'WebNLG: '+row['input_text']+'</s>' \n",
    "                    labels = row['target_text']+'</s>'   \n",
    "                    inputbatch.append(input)\n",
    "                    labelbatch.append(labels)\n",
    "\n",
    "                if len(inputbatch) < 1:\n",
    "                    continue\n",
    "                inputbatch = self.tokenizer.batch_encode_plus(inputbatch,padding=True,max_length=400,return_tensors='pt')[\"input_ids\"]\n",
    "                labelbatch = self.tokenizer.batch_encode_plus(labelbatch,padding=True,max_length=400,return_tensors=\"pt\") [\"input_ids\"]\n",
    "                inputbatch = inputbatch.to(self.dev)\n",
    "                labelbatch = labelbatch.to(self.dev)\n",
    "\n",
    "                self.optimizer.zero_grad()\n",
    "\n",
    "                outputs = self.model(input_ids=inputbatch, labels=labelbatch)\n",
    "                loss = outputs.loss\n",
    "                loss_num = loss.item()\n",
    "                logits = outputs.logits\n",
    "                running_loss += loss_num\n",
    "                if i%10 ==0:\n",
    "                    loss_per_10_steps.append(loss_num)\n",
    "                out.update(self.progress(loss_num, i, self.num_of_batches+1))\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "            running_loss = running_loss/int(self.num_of_batches)\n",
    "            print('Epoch: {} , Running loss: {}'.format(epoch,running_loss))\n",
    "        self.saveModel()\n",
    "        self.emptyCudaCache()\n",
    "\n",
    "    def saveModel(self):\n",
    "        torch.save(self.model.state_dict(), self.checkpoint_path)\n",
    "    \n",
    "    def loadModel(self):\n",
    "        return T5ForConditionalGeneration.from_pretrained(self.checkpoint_path, return_dict=True, config=self.config_path)\n",
    "    \n",
    "    def emptyCudaCache(self):\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    def generate(self, text):\n",
    "        torch.manual_seed(0)\n",
    "        model = self.loadModel()\n",
    "        model.eval()\n",
    "        input_ids = self.tokenizer.encode(\"WebNLG:{} </s>\".format(text), return_tensors=\"pt\")\n",
    "        sample_outputs = model.generate(\n",
    "            input_ids,\n",
    "            do_sample=True,\n",
    "            max_length=50, \n",
    "            top_k=4, \n",
    "            top_p=0.99,\n",
    "            num_return_sequences=10\n",
    "        )\n",
    "\n",
    "        print(\"Output:\\n\" + 100 * '-')\n",
    "        for i, sample_output in enumerate(sample_outputs):\n",
    "          print(\"{}: {}\".format(i, self.tokenizer.decode(sample_output, skip_special_tokens=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "58876a92-85dd-4bdf-8ef0-781dfafdaa24",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = ContentGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "32aabd9f-7a54-4a69-a4c1-1bf3434cf4d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on the CPU\n",
      "Running epoch: 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       " Batch loss :1.4618747234344482\n",
       "            <progress\n",
       "                value='61'\n",
       "                max='63',\n",
       "                style='width: 100%'\n",
       "            >\n",
       "                61\n",
       "            </progress>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 , Running loss: 1.8760927684845463\n",
      "Running epoch: 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       " Batch loss :0.9028013348579407\n",
       "            <progress\n",
       "                value='61'\n",
       "                max='63',\n",
       "                style='width: 100%'\n",
       "            >\n",
       "                61\n",
       "            </progress>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 , Running loss: 1.0149331294721173\n",
      "Running epoch: 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       " Batch loss :0.5100981593132019\n",
       "            <progress\n",
       "                value='61'\n",
       "                max='63',\n",
       "                style='width: 100%'\n",
       "            >\n",
       "                61\n",
       "            </progress>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 , Running loss: 0.6511879577752082\n",
      "Running epoch: 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       " Batch loss :0.2851283550262451\n",
       "            <progress\n",
       "                value='61'\n",
       "                max='63',\n",
       "                style='width: 100%'\n",
       "            >\n",
       "                61\n",
       "            </progress>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 , Running loss: 0.44876767178216287\n",
      "Running epoch: 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       " Batch loss :0.16632257401943207\n",
       "            <progress\n",
       "                value='61'\n",
       "                max='63',\n",
       "                style='width: 100%'\n",
       "            >\n",
       "                61\n",
       "            </progress>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 , Running loss: 0.3281198222069971\n",
      "Running epoch: 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       " Batch loss :0.11898235231637955\n",
       "            <progress\n",
       "                value='61'\n",
       "                max='63',\n",
       "                style='width: 100%'\n",
       "            >\n",
       "                61\n",
       "            </progress>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6 , Running loss: 0.25544375127121327\n",
      "Running epoch: 7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       " Batch loss :0.08666442334651947\n",
       "            <progress\n",
       "                value='61'\n",
       "                max='63',\n",
       "                style='width: 100%'\n",
       "            >\n",
       "                61\n",
       "            </progress>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7 , Running loss: 0.21032490617325228\n",
      "Running epoch: 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       " Batch loss :0.06776001304388046\n",
       "            <progress\n",
       "                value='61'\n",
       "                max='63',\n",
       "                style='width: 100%'\n",
       "            >\n",
       "                61\n",
       "            </progress>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8 , Running loss: 0.1724404438789333\n",
      "Running epoch: 9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       " Batch loss :0.05875800549983978\n",
       "            <progress\n",
       "                value='61'\n",
       "                max='63',\n",
       "                style='width: 100%'\n",
       "            >\n",
       "                61\n",
       "            </progress>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9 , Running loss: 0.13932882042060937\n",
      "Running epoch: 10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       " Batch loss :0.051828354597091675\n",
       "            <progress\n",
       "                value='61'\n",
       "                max='63',\n",
       "                style='width: 100%'\n",
       "            >\n",
       "                61\n",
       "            </progress>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 , Running loss: 0.11538848540775719\n"
     ]
    }
   ],
   "source": [
    "obj.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "658ed4cb-605a-458e-ac47-795012f10fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = ContentGenerator()\n",
    "obj.getTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5f0100fc-9a11-4dea-9ba0-8f3e8dff695b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "0: I just LOVE this shampoo! No more chemicals, no added chemicals, no added chemicals, no added chemicals, no added chemicals, no added chemicals, no added chemicals, no added chemicals, no added chemicals, no added chemicals,\n",
      "1: Shampoo is a wonderful shampoo. It makes my skin feel really clean and soft. No chemicals, no pesticides, or preservatives and not tested on animals.\n",
      "2: Shampoo uses only the purest of ingredients and not chemically based on any other product. This enables me to use only the best of the best and most effective shampoo ever made. No added chemicals nor preservative\n",
      "3: Shampoo uses nothing more than a simple change of the skin (except for the shampoo itself). This is not a great shampoo, it doesn't make your skin red or dry, but it does produce\n",
      "4: Shampoo can cause skin changes that can cause skin cancer. Useful shampoo can be helpful but not harmful.\n",
      "5: I have used this shampoo for years, I was first introduced to it in Madera in the early 90's and for some years had them ship me the Shampoo Patch. It's really nice and doesn't make\n",
      "6: This shampoo is a wonderful shampoo that doesn't make your skin break out or cause a chemical reaction. It doesn't make your skin feel \"clean\" anymore, its just like a normal\n",
      "7: Shampoo has been used as a shampoo since the late 90's & early 2000's. It is not harmful to your skin or any harmful chemicals.\n",
      "8: Smells amazing! I have been using it for about 10 years and I was first introduced to it in Madera in the early 90's and for some years had them ship me the Shampoo. I am slowly becoming completely\n",
      "9: Shampoo uses only a small amount of the Shampoo in them. It is not greasy, it makes your skin very soft and doesn't make any changes. Don't let it get any worse. No more harmful than your\n"
     ]
    }
   ],
   "source": [
    "key = 'shampoo | change | skin | harmful'\n",
    "obj.generate(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eafe4c6-6301-4afe-b8dd-c831609df420",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
